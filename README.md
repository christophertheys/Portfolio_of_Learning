# Portfolio_of_Learning
Developing a portfolio of learning that shows my competency development and understanding of Health Analytics ðŸ©º

Personal Statement and Reflection

Harnessing the power of numbers as a Chartered Accountant (ACCA), my personal goals are aimed at unlocking the mysteries wrapped in data through the lens of data science and machine learning. With my core strengths in accounting, finance, and mathematics, coupled with an interest in coding, my adventure into the world of data science, has been both enlightening and transformative.

My affinity for integrating software, data, and analytics has evolved into a particular interest in data science and machine learning principles. Through the course of the Post Graduate Diploma in Data Science, exploring health analytics emerged as a new field, expanding my academic and professional horizons. Prior to my academic endeavors in data science, my insight into health analytics was notably sparse, confined to a minimal understanding of public healthcare in South Africa. 
This limited perception was accumulated predominantly through family connections, with relatives serving in pivotal roles as Director Generals in the public healthcare sector. Consequently, my knowledge was rooted more in administrative and policy-oriented aspects, rather than the analytical and data-driven dimensions now being explored through my current studies.

By delving deeper into basic concepts of health analytics, I explored and understood the complexities of supervised and unsupervised machine learning. Supervised learning, in which algorithms are trained using labeled data, and unsupervised learning, in which algorithms explore unlabeled data to discover hidden patterns. These concepts have paved the way for valuable insights, including predicting and understanding patient outcomes, optimizing operational efficiency, and uncovering risk potential elements within health datasets.

## Defining Health Analytics

Defining Health Analytics

Embarking on a deep dive into the realm of health analytics through my Post Graduate Diploma in Data Science, my understanding of this field has been holistically shaped by a series of assignments that intertwined the theoretical knowledge with hands-on application. 

Initially, defining the foundational building blocks of a Health System through visual representation on a Miro Board, followed by crafting an essay to explore Contemporary Health Systems Challenges, set the initial stage of understanding the current healthcare setting and its inherent complexities. This was effectively contrasted with practical tasks, such as employing Python libraries like pandas and numpy to dissect datasets and leveraging Matplotlib for data visualization, which not only amplified my technical skillset but also enabled me to draw tangible correlations between data and healthcare quality improvement. 



The courses also helped me understand the important role of data science in health systems science, through identifying and establishing the necessary skills of a health analyst, whilst concurrently illuminating my growth areas through practical application. 

Leveraging different tools and technologies, such as cloud computing and markup, I deciphered the dominant technology groups in data analytics and contextualized the current state of data analytics in the medical field. As I navigate the various types of medical data sources and meticulously analyzed electronic health records, I learnt to place a significant emphasis on evaluating, preparing, and managing data quality, including developing strategic methods to eliminate null values and prepares data for multifaceted analyses.

My journey also delved into the technicalities of managing dataset dimensions, where I applied Principal Component Analyses (PCA) and clustering algorithms such as K-means to principal components from datasets, consequently enhancing my practical understanding of both supervised and unsupervised learning methodologies. 

The program naturally evolved to address critical aspects like data security, ensuring that my insights into health analytics are not only rooted in optimizing data utility but also safeguarding sensitive information, thereby synthesizing technical know-how with ethical practice. Consequently, this multifaceted approach has scaffolded my transition from a nascent understanding of health analytics to developing a robust, hands-on expertise that cohesively intertwines technical proficiency with a comprehensive understanding of healthcare systems and challenges.


## Addressing Contemporary Health Challenges: The Role of Data Science

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/dc0d4d3bc57171a82e50ccbf304d7b7b432f2f18/1834424%20Contemporary%20Health%20challenge.pdf 

A comprehensive review of a contemporary health challenges, within the South African context.

## Lab 1 

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/4515591f638bcff1b5c9cc6b39de91fbc9fd6807/Notebook%20Lab%201%20V4.ipynb 

Lab 1 Reflection - 
Embarking upon an assignment that melded theoretical knowledge with applied skills, for this group task we delved deeply into the nuances of linear regression modelling, utilizing a carefully selected dataset as the bedrock for our exploration. 

The initial phase demanded meticulous analysis of the dataset, wherein we dedicated substantial efforts towards understanding its features, distribution, and potential predictors. Upon selecting a relevant dataset, the journey ventured into practical implementation, utilizing Python libraries such as numpy, matplotlib, and sklearn to materialize a linear regression model. Here, we were able to put theory into practice, initializing the model, fitting it with data, and ultimately observing the resultant predictions and residuals. 

This practical aspect not only solidified my understanding of the algorithmâ€™s workings but also provided invaluable hands-on experience with coding and model implementation. Furthermore, throughout the implementation, each decision-making junctureâ€”from selecting independent and dependent variables, pre-processing data, to tuning the modelâ€”was anchored by thorough justification and clear delineation of the process followed. This required weaving theoretical knowledge of linear regression, gleaned from course materials, with the practical challenges and considerations encountered during implementation. 

## Activity 1 - Exploring Data Types, Analysis Tools, and Learning in Health Analysis

Link to slide show and embedded audio recording: https://github.com/christophertheys/Portfolio_of_Learning/blob/f663d048433557d2fad1293c02ec853ee53e2c17/1834424%20Activity%201%20Slide%20Show.pptx

Download Raw File to access and download slideshow on Powerpoint 

## Online Revision Session for Lab 1

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/4688bfc939d5d81813ef10e72534c4114b56bf62/Online%20Revision%20Session%20for%20Lab%201.pdf 

## Types of Data 

Types of Data Reflection â€“ Exploring Data

Disease Classification - Algorithms can be trained to classify diseases like tumours as malignant or benign. This uses categorical data as the outcome is typically a distinct category.

Prediction of Patient Readmission Rates - Hospitals might use patient data to predict the likelihood of a patient being readmitted within a certain time frame. This would be categorical data. 

Blood Sugar Level - Machine learning models can predict future blood sugar levels. This problem leverages continuous data as blood sugar levels are measured on a continuous scale. 

Estimation of Drug Response - Analysing patient genetics and other biomarkers, machine learning models can be designed to predict how a patient will respond to a particular medication. This would be classified as categorical data as either a positive response, neutral response, or a negative response. 

Progression Tracking of Neurological Diseases â€“ Diseases such as Parkinson's or Alzheimer's, machine learning models can be utilised to analyse patient data and predict the rate of disease progression. This uses continuous data, because the disease progression will be measured on a continuous basis.  

## Lab 2 

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/105c3aa8d886238bc1848a987fa81eaf1b92685a/1834424_Lab2_logisticregression.ipynb

Lab 2 Reflection

Participating in Lab 2, the objective of the task was undertaking a process of building a complex logistic regression model, starting with the important step of feature selection. Together, we used different feature selection techniques, such as recursive feature elimination and using feature importance scores, with the aim of distilling the most relevant predictors for our model.

Navigating the group's tasks proved to be a difficult task as we faced significant obstacles in our collective working dynamics, especially in the area of communication. The lack of consistent and clear communication between us often disrupts our workflow, creating not only procedural obstacles but also affecting the  synergy and efficiency of our efforts. our collaborative efforts. This common problem has highlighted the urgent need to establish strong communication channels and standards in future collaborative projects.

Transitioning to model implementation, utilizing numpy, matplotlib, and sklearn libraries allowed us to not only apply theoretical knowledge practically but also deepen our collective understanding of logistic regression's functional form and optimization procedures. 

The subsequent model optimization posed a challenging yet enlightening experience, wherein we navigated through hyper-parameter tuning and regularisation techniques. While being mindful of the dataset's characteristics and the peril of overfitting, our group strategically employed techniques like GridSearchCV for hyperparameter tuning and implemented L1 and L2 regularization, ensuring our model was both accurate and generalizable to unseen data. 

## Activity 2 - Using Health Analytics in a Healthcare Setting

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/4e1c9c28db87068364a5adfcc71a6b7c4453d5c3/1834424%20Activity%202%20.pdf 

Reflection

I focused my lens on Johns Hopkins Hospital, which has manifested tangible competitive and life-saving advantages through its strategic deployment of health analytics. Sourcing information through a myriad of academic articles, industry reports, and case studies, my exploration uncovered how health analytics has been vital, not only in shaping superior health outcomes but also in driving operational excellence within such establishments.

Whilst crafting a presentation highlighting Johns Hopkins Hospital, I gained intricate insights into the multifaceted ways through which the organization adeptly utilizes health analytics to achieve varied outcomes. This includes amplification of patient care, optimization of operations, cost reduction, and the preservation of lives. A particularly remarkable discovery was the extensive and profound array of data sources exploited, ranging from Electronic Health Records (EHRs) to patient feedback surveys and numerous additional data points, all of which were thoroughly analysed to extract meaningful insights and perpetuate an ethos of continuous enhancement.
Navigating through the specific tools and approaches employed, I uncovered a panorama of analytics initiatives, ranging from predictive analytics for patient outcomes, operational analytics for resource optimization, to prescriptive analytics for enhanced decision-making across the healthcare value chain. Johns Hopkins Hospitalâ€™s endeavours to intricately intertwine data and analytical tools, like machine learning algorithms and data visualization, into their operational and clinical frameworks. This offered a profound insight into the impact data can have on healthcare delivery and management.

Some challenges were also identified that the healthcare organizations encounter in their health analytics journeys. Data privacy, exchange of data, and management emerged as prevailing hurdles. Johns Hopkins Hospital, in this context, illuminated how these challenges can be adeptly managed through robust data governance, stringent security protocols, and fostering a culture that seamlessly blends clinical expertise with analytical acumen.

Reflecting upon this exploration, the lessons extend beyond the technical and strategic facets of health analytics. This task emphasized the vital role that data and analytics play in enhancing healthcare outcomes and operational efficacy. Furthermore, it has instilled a deeper appreciation for the complexity and multifaceted nature of implementing health analytics within organizations, thereby shaping a well-rounded perspective that connects technical, strategic, and ethical considerations in the realm of health analytics. 

## Lab 3 - Breast Cancer Prediction Using Decision Tree

Hyperlink: https://github.com/christophertheys/Portfolio_of_Learning/blob/f8e1c3c2ca626becc791c2bd60bbfd5d1614e374/HealthAnalytics_Lab3FINAL.ipynb 

- Background on breast cancer 

Breast cancer is one of the most common cancers worldwide, predominantly affecting women, although men can also be diagnosed with this type of cancer. It arises from the cells of the breast, often from the inner lining of milk ducts or the lobules that supply these ducts with milk. The World Health Organization reports that breast cancer impacts over 2.1 million women each year, marking it as a major global health concern. 
In this comprehensive report, we delineate the findings derived from employing a decision tree algorithm in the predictive analysis of breast cancer incidences. Through meticulous data preparation and model optimization, we strive to leverage the decision tree algorithmâ€™s capabilities to foster substantial advancements in predictive diagnostics, thereby demonstrating the potential of this model as a pivotal tool in mitigating the global health challenge posed by breast cancer. 

- The Data 

We used a dataset found at which contained 569 rows and 32 columns containing information from breast mass biopsy samples. The dataset also has the target variable of diagnosis, which we are trying to predict whether the observation is benign or malignant based on the other attributes. 
For this study, we utilized a dataset retrieved from, https://data.world/health/breastcancer- Wisconsin, which encompasses 569 instances and 32 attributes derived from breast mass biopsy samples. Each instance in this dataset represents critical data gathered from individual biopsy samples, with a range of attributes that facilitate a detailed analysis aimed at the predictive diagnosis of breast cancer. 
The pivotal component of this dataset is the target variable denominated as 'diagnosis', establishing the binary classification that we aim to predict; benign or malignant. 

- The Process 

Suite of Libraries 
NumPy: Engaged for efficient handling of arrays and matrices, which is essential in managing our dataset efficiently. 
Pandas: Utilized for data manipulation and analysis, aiding in cleaning, and organizing our dataset for optimal performance. 
Matplotlib: Employed for crafting visualizations to better understand our data and to create graphical representations of our findings. 
Seaborn: Leveraged in conjunction with Matplotlib to enhance the visualization of data through the creation of aesthetically pleasing and informative statistical graphics. 
Scikit-learn (sklearn): This library played a pivotal role, offering a range of tools used throughout the process. Splitting our data into training and test sets, a critical step in training our decision tree model.
Within this library: 
* Modules aided in feature selection, helping identify the most relevant attributes for our predictive model. o Served as the foundation of our decision tree model, facilitating the training, and testing process. 
* Facilitated the hyperparameter tuning process, helping optimize the model for better performance. 

- Preliminary Data Analysis 

We ensured that the dataset doesnâ€™t have any duplicate observations and that all the required attributes are available. 
A detailed error message that specifies which columns are missing is generated using a formatted string that joins the names of the missing columns with a comma. This approach ensures that the script will halt execution and alert the user to the specific issue, thereby preventing silent failures and facilitating debugging. 

- Exploring the Data 

To get a better understanding of the dataset we examined the data visually and statistically to uncover patterns, relationships, and potential outliers. 

- Preparing the Data 

The dataset underwent pre-processing which included steps such as duplication, the elimination of irrelevant columns, and the creation of a numerical depiction through correlation analysis. Additionally, the relations between different features were visualized, and verification was carried out to confirm the accurate representation of various classes in the 'diagnosis' column. 

- Feature Selection and Analysis 
Based on the insights gained from exploring the data and further analysis we determined which features were most relevant for predicting breast cancer. In the initial stage of our feature selection process, we undertook a systematic exploration of each numerical attribute in our dataset to gain a foundational understanding of the underlying distributions and to identify potential outliers that could influence our modelâ€™s performance. 

Distribution Analysis: 
This step was crucial in understanding the data distribution, which could influence the feature selection based on the specific patterns or distributions observed. 

Subsequently, we utilized Seaborn's boxplot function to create boxplots for each numerical column, providing a graphic representation of the central tendency and variability of the data, alongside showcasing potential outliers. 

Correlation Analysis: 
The correlation matrix helps you identify relationships between features. High correlations between features can indicate multicollinearity, which may affect the model's performance. This analysis aids in selecting features that are less correlated with each other. 

- Implementing the Decision Tree Algorithm 

Per the assignment requirements, we were tasked to implement a decision tree model using numpy, matplotlib, or Sklearn libraries. Scikit-learn's DecisionTreeClassifier typically employs an optimized version of the CART (Classification and Regression Trees) algorithm. The CART algorithm is efficient and scalable, making it suitable for datasets of various sizes. 
Implementing the decision tree algorithm involved training the decision tree algorithm on the data. This allows the algorithm to learn from the dataset how to distinguish between benign and malignant cases based on the features we provided. 
The classifier is trained utilizing the training dataset, thereby learning the underlying patterns present within the data. This knowledge equips the classifier with the ability to accurately forecast outcomes on previously unseen data. 

- Model Optimization and Hyper-parameter Tuning 

The objective is to enhance the decision tree model by identifying and incorporating the best hyperparameters, ultimately improving the model's ability to make accurate predictions. 
Including a varied range of values for these hyperparameters ensures that the grid search can explore a broad space of possible models, which is essential to finding a well-tuned model 

- Results 

Our model was assessed using various metrics to evaluate its performance: 
The model achieved an accuracy score of approximately 90.06%. Accuracy, however, isn't a good metric especially for imbalanced datasets and applications like medical diagnosis. It was then important to consider other metrics like precision, recall, and the confusion matrix to properly evaluate model performance. 

Confusion Matrix 

The confusion matrix provides insights into the model's ability to make accurate predictions. 
In our case: [100 7] [10 54] 

* The top left cell (100) represents true negatives (benign cases correctly predicted)
* The top right cell (7) represents false positives (benign cases predicted as malignant)
* The bottom left cell (10) represents false negatives (malignant cases predicted as benign)
* The bottom right cell (54) represents true positives (malignant cases correctly predicted) 

The model achieved a precision score of 89%. Precision measures the accuracy of positive predictions (Malignant). The model achieved a recall score of 84%, it indicates that 84% of the actual malignant cases were correctly identified. 

After hyperparameter tuning for our decision tree model, the model correctly predicted the outcomes for approximately 93% of the test cases. This means that hyperparameter tuning helped improve the modelâ€™s performance. The metrics indicate that our model is highly effective at identifying whether a patient has breast cancer or not. 

## Activity 5 - PCA biomedical data

Hyperlink to Jupyter Notebook:

Hyperlink to Reflection: 








